{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weakly Supervised Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments steps:\n",
    " 1. **User's Preferences Model**: Leverage the most *explicit* ratings to build a *rate/rank prediction model*. This is a simple *Explicit Matrix Factorization* model. \n",
    " 2. **Generate Weak DataSet**: Use the above model to *predict* for all user/item pairs $(u,i)$ in *implicit feedback dataset* to build a new *weak explicit dataset* $(u, i, r^*)$.\n",
    " 3. **Evaluate**: Use the intact test split in the most explicit feedback, in order to evaluate the performance of any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains all the experiments based on the explicit matrix factorization model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Rate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit dataset (TEST) contains 412,459 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (VALID) contains 412,460 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (TRAIN) contains 3,299,673 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (READ) contains 4,293,460 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (SHELVE) contains 6,022,657 interactions of 81,172 users and 88,857 items\n",
      "--------------------\n",
      "RMSE: 0.3775\n",
      "MRR: 0.0381\n",
      "nDCG: 0.0443\n",
      "nDCG@10: 0.0318\n",
      "nDCG@5: 0.0202\n",
      "MAP: 0.0189\n",
      "success@10: 0.1239\n",
      "success@5: 0.0653\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "dataset_recommend_train, dataset_recommend_test, dataset_recommend_dev, dataset_read, dataset_shelve = utils.parse_goodreads(\n",
    "    path='/local/terrier/Collections/Recommendations/Goodreads/goodreads_interactions_comics_graphic.json.gz')\n",
    "\n",
    "print('Explicit dataset (TEST) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_test.ratings), ','),\n",
    "          format(dataset_recommend_test.num_users, ','),\n",
    "          format(dataset_recommend_test.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (VALID) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_dev.ratings), ','),\n",
    "          format(dataset_recommend_dev.num_users, ','),\n",
    "          format(dataset_recommend_dev.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (TRAIN) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_train.ratings), ','),\n",
    "          format(dataset_recommend_train.num_users, ','),\n",
    "          format(dataset_recommend_train.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (READ) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_read.ratings), ','),\n",
    "          format(dataset_read.num_users, ','),\n",
    "          format(dataset_read.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (SHELVE) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_shelve.ratings), ','),\n",
    "          format(dataset_shelve.num_users, ','),\n",
    "          format(dataset_shelve.num_items, ',')))\n",
    "\n",
    "# train the explicit model based on recommend feedback\n",
    "model = utils.train_explicit(train_interactions=dataset_recommend_train, \n",
    "                             valid_interactions=dataset_recommend_dev,\n",
    "                             run_name='model_goodreads_comics_explicit_rate')\n",
    "\n",
    "# evaluate the new model\n",
    "mrr, ndcg, ndcg10, ndcg_5, mmap, success_10, success_5 = utils.evaluate(interactions=dataset_recommend_test,\n",
    "                                                                        model=model,\n",
    "                                                                        topk=20)\n",
    "rmse = rmse_score(model=model, test=dataset_recommend_test)\n",
    "print('-'*20)\n",
    "print('RMSE: {:.4f}'.format(rmse))\n",
    "print('MRR: {:.4f}'.format(mrr))\n",
    "print('nDCG: {:.4f}'.format(ndcg))\n",
    "print('nDCG@10: {:.4f}'.format(ndcg10))\n",
    "print('nDCG@5: {:.4f}'.format(ndcg_5))\n",
    "print('MAP: {:.4f}'.format(mmap))\n",
    "print('success@10: {:.4f}'.format(success_10))\n",
    "print('success@5: {:.4f}'.format(success_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all valid/test ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interact = set()\n",
    "for (uid, iid) in zip(dataset_recommend_test.user_ids, dataset_recommend_test.item_ids):\n",
    "    test_interact.add((uid, iid))\n",
    "\n",
    "for (uid, iid) in zip(dataset_recommend_dev.user_ids, dataset_recommend_dev.item_ids):\n",
    "    test_interact.add((uid, iid))\n",
    "\n",
    "# clean implicit dataset from test/dev rating\n",
    "for idx, (uid, iid, r) in enumerate(zip(dataset_read.user_ids, dataset_read.item_ids, dataset_read.ratings)):\n",
    "    if (uid, iid) in test_interact:\n",
    "        dataset_read.ratings[idx] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit Read Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage the **explicit rate model** trained at the previous section to annotate **missing values** in the **read** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 start at:  Tue Apr 23 11:18:42 2019\n",
      "epoch 1 end at:  Tue Apr 23 11:20:56 2019\n",
      "RMSE: 0.3850\n",
      "epoch 2 start at:  Tue Apr 23 11:21:01 2019\n",
      "epoch 2 end at:  Tue Apr 23 11:23:16 2019\n",
      "RMSE: 0.3836\n",
      "epoch 3 start at:  Tue Apr 23 11:23:21 2019\n",
      "epoch 3 end at:  Tue Apr 23 11:25:35 2019\n",
      "RMSE: 0.3901\n",
      "--------------------\n",
      "RMSE: 0.3903\n",
      "MRR: 0.0773\n",
      "nDCG: 0.0663\n",
      "nDCG@10: 0.0575\n",
      "nDCG@5: 0.0487\n",
      "MAP: 0.0386\n",
      "success@10: 0.1709\n",
      "success@5: 0.1219\n"
     ]
    }
   ],
   "source": [
    "# annotate the missing values in the play dataset based on the explicit recommend model\n",
    "dataset_read = utils.annotate(interactions=dataset_read, \n",
    "                              model=model, \n",
    "                              run_name='dataset_goodreads_comics_read_explicit_annotated')\n",
    "\n",
    "# train the explicit model based on recommend feedback\n",
    "model = utils.train_explicit(train_interactions=dataset_read, \n",
    "                             valid_interactions=dataset_recommend_dev,\n",
    "                             run_name='model_goodreads_comics_explicit_read')\n",
    "\n",
    "# evaluate the new model\n",
    "mrr, ndcg, ndcg10, ndcg_5, mmap, success_10, success_5 = utils.evaluate(interactions=dataset_recommend_test,\n",
    "                                                                        model=model,\n",
    "                                                                        topk=20)\n",
    "rmse = rmse_score(model=model, test=dataset_recommend_test)\n",
    "print('-'*20)\n",
    "print('RMSE: {:.4f}'.format(rmse))\n",
    "print('MRR: {:.4f}'.format(mrr))\n",
    "print('nDCG: {:.4f}'.format(ndcg))\n",
    "print('nDCG@10: {:.4f}'.format(ndcg10))\n",
    "print('nDCG@5: {:.4f}'.format(ndcg_5))\n",
    "print('MAP: {:.4f}'.format(mmap))\n",
    "print('success@10: {:.4f}'.format(success_10))\n",
    "print('success@5: {:.4f}'.format(success_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Model Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains all the experiments based on the implicit matrix factorization model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit Model using Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit dataset (TEST) contains 412,459 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (VALID) contains 412,460 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (TRAIN) contains 3,299,673 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (READ) contains 4,293,460 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (SHELVE) contains 6,022,657 interactions of 81,172 users and 88,857 items\n",
      "epoch 1 start at:  Sat Apr 20 12:26:55 2019\n",
      "epoch 1 end at:  Sat Apr 20 12:31:14 2019\n",
      "MRR: 0.0666\n",
      "epoch 2 start at:  Sat Apr 20 12:54:06 2019\n",
      "epoch 2 end at:  Sat Apr 20 12:56:43 2019\n",
      "MRR: 0.0666\n",
      "epoch 3 start at:  Sat Apr 20 13:19:17 2019\n",
      "epoch 3 end at:  Sat Apr 20 13:21:54 2019\n",
      "MRR: 0.0644\n",
      "--------------------\n",
      "RMSE: 3.6611\n",
      "MRR: 0.0637\n",
      "nDCG: 0.0522\n",
      "nDCG@10: 0.0412\n",
      "nDCG@5: 0.0325\n",
      "MAP: 0.0256\n",
      "success@10: 0.1563\n",
      "success@5: 0.0950\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "dataset_recommend_train, dataset_recommend_test, dataset_recommend_dev, dataset_read, dataset_shelve = utils.parse_goodreads(\n",
    "    path='/local/terrier/Collections/Recommendations/Goodreads/goodreads_interactions_comics_graphic.json.gz')\n",
    "\n",
    "print('Explicit dataset (TEST) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_test.ratings), ','),\n",
    "          format(dataset_recommend_test.num_users, ','),\n",
    "          format(dataset_recommend_test.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (VALID) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_dev.ratings), ','),\n",
    "          format(dataset_recommend_dev.num_users, ','),\n",
    "          format(dataset_recommend_dev.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (TRAIN) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_train.ratings), ','),\n",
    "          format(dataset_recommend_train.num_users, ','),\n",
    "          format(dataset_recommend_train.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (READ) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_read.ratings), ','),\n",
    "          format(dataset_read.num_users, ','),\n",
    "          format(dataset_read.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (SHELVE) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_shelve.ratings), ','),\n",
    "          format(dataset_shelve.num_users, ','),\n",
    "          format(dataset_shelve.num_items, ',')))\n",
    "\n",
    "# train the explicit model based on recommend feedback\n",
    "model = utils.train_implicit_negative_sampling(train_interactions=dataset_read, \n",
    "                                               valid_interactions=dataset_recommend_dev,\n",
    "                                               run_name='model_goodreads_comics_implicit')\n",
    "\n",
    "# evaluate the new model\n",
    "mrr, ndcg, ndcg10, ndcg_5, mmap, success_10, success_5 = utils.evaluate(interactions=dataset_recommend_test,\n",
    "                                                                        model=model,\n",
    "                                                                        topk=20)\n",
    "rmse = rmse_score(model=model, test=dataset_recommend_test)\n",
    "print('-'*20)\n",
    "print('RMSE: {:.4f}'.format(rmse))\n",
    "print('MRR: {:.4f}'.format(mrr))\n",
    "print('nDCG: {:.4f}'.format(ndcg))\n",
    "print('nDCG@10: {:.4f}'.format(ndcg10))\n",
    "print('nDCG@5: {:.4f}'.format(ndcg_5))\n",
    "print('MAP: {:.4f}'.format(mmap))\n",
    "print('success@10: {:.4f}'.format(success_10))\n",
    "print('success@5: {:.4f}'.format(success_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit dataset (TEST) contains 412,459 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (VALID) contains 412,460 interactions of 81,172 users and 88,857 items\n",
      "Explicit dataset (TRAIN) contains 3,299,673 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (READ) contains 4,293,460 interactions of 81,172 users and 88,857 items\n",
      "Implicit dataset (SHELVE) contains 6,022,657 interactions of 81,172 users and 88,857 items\n",
      "fit the model\n",
      "evaluate the model\n",
      "MRR: 0.0554\n",
      "nDCG: 0.0458\n",
      "nDCG@10: 0.0359\n",
      "nDCG@5: 0.0291\n",
      "MAP: 0.0233\n",
      "success@10: 0.1279\n",
      "success@5: 0.0814\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from spotlight.evaluation import rmse_score\n",
    "from popularity import PopularityModel\n",
    "\n",
    "dataset_recommend_train, dataset_recommend_test, dataset_recommend_dev, dataset_read, dataset_shelve = utils.parse_goodreads(\n",
    "    path='/local/terrier/Collections/Recommendations/Goodreads/goodreads_interactions_comics_graphic.json.gz')\n",
    "\n",
    "print('Explicit dataset (TEST) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_test.ratings), ','),\n",
    "          format(dataset_recommend_test.num_users, ','),\n",
    "          format(dataset_recommend_test.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (VALID) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_dev.ratings), ','),\n",
    "          format(dataset_recommend_dev.num_users, ','),\n",
    "          format(dataset_recommend_dev.num_items, ',')))\n",
    "\n",
    "print('Explicit dataset (TRAIN) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_recommend_train.ratings), ','),\n",
    "          format(dataset_recommend_train.num_users, ','),\n",
    "          format(dataset_recommend_train.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (READ) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_read.ratings), ','),\n",
    "          format(dataset_read.num_users, ','),\n",
    "          format(dataset_read.num_items, ',')))\n",
    "\n",
    "print('Implicit dataset (SHELVE) contains %s interactions of %s users and %s items'%(\n",
    "          format(len(dataset_shelve.ratings), ','),\n",
    "          format(dataset_shelve.num_users, ','),\n",
    "          format(dataset_shelve.num_items, ',')))\n",
    "\n",
    "# train the explicit model based on recommend feedback\n",
    "model = PopularityModel()\n",
    "print('fit the model')\n",
    "model.fit(interactions=dataset_recommend_train)\n",
    "\n",
    "# evaluate the new model\n",
    "print('evaluate the model')\n",
    "mrr, ndcg, ndcg10, ndcg_5, mmap, success_10, success_5 = utils.evaluate(interactions=dataset_recommend_test,\n",
    "                                                                        model=model,\n",
    "                                                                        topk=20)\n",
    "# rmse = rmse_score(model=model, test=dataset_recommend_test, batch_size=512)\n",
    "# print('-'*20)\n",
    "# print('RMSE: {:.4f}'.format(rmse))\n",
    "print('MRR: {:.4f}'.format(mrr))\n",
    "print('nDCG: {:.4f}'.format(ndcg))\n",
    "print('nDCG@10: {:.4f}'.format(ndcg10))\n",
    "print('nDCG@5: {:.4f}'.format(ndcg_5))\n",
    "print('MAP: {:.4f}'.format(mmap))\n",
    "print('success@10: {:.4f}'.format(success_10))\n",
    "print('success@5: {:.4f}'.format(success_5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
